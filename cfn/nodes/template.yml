---
AWSTemplateFormatVersion: '2010-09-09'
Description: 'EKS nodes (AMI family: AmazonLinux2, SSH access: false, subnet topology: Public)'

Parameters:

  VpcName:
    Description: The vpc name to associate resources with
    Type: String

  ClusterName:
    Description: The cluster name provided when the cluster was created. If it is incorrect, nodes will not be able to join the cluster.
    Type: String

  NodeGroupMinSize:
    Type: String
    Default: "1"
  NodeGroupMaxSize:
    Type: String
    Default: "10"
  NodeVolumeSize:
    Type: Number
    Description: Node volume size
    Default: 20
  NodeImageId:
    Type: AWS::EC2::Image::Id
    Description: AMI id for the node instances.
  NodeInstanceType:
    Description: EC2 instance type for the node instances
    Type: String
    Default: t3.large
  NodeSshKeyName:
    Description: The EC2 Key Pair to allow SSH access to the instances
    Type: AWS::EC2::KeyPair::KeyName
  BootstrapArguments:
    Description: Arguments to pass to the bootstrap script. See files/bootstrap.sh in https://github.com/awslabs/amazon-eks-ami
    Default: ""
    Type: String

Resources:

  NodeGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      AutoScalingGroupName: !Sub kube-${ClusterName}-nodes
      LaunchConfigurationName: !Ref 'NodeLaunchConfig'
      MaxSize: !Ref NodeGroupMaxSize
      MinSize: !Ref NodeGroupMinSize
      Tags:
        - Key: Name
          Value: !Sub ${ClusterName}-nodes
          PropagateAtLaunch: 'true'
        - Key: !Sub kubernetes.io/cluster/${ClusterName}
          Value: owned
          PropagateAtLaunch: 'true'
      VPCZoneIdentifier: !Split
        - ','
        - Fn::ImportValue:
            !Sub KubeClusterPrivateSubnets-${VpcName}
    CreationPolicy:
      AutoScalingCreationPolicy:
        MinSuccessfulInstancesPercent: 100
      ResourceSignal:
        Count: !Ref NodeGroupMinSize
        Timeout: PT5M
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MaxBatchSize: '1'
        MinInstancesInService: !Ref NodeGroupMinSize
        PauseTime: 'PT5M'
        WaitOnResourceSignals: true

  NodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - Fn::ImportValue:
            !Sub KubeCluster-NodeInstanceRole-${ClusterName}

  NodeLaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Metadata:
      AWS::CloudFormation::Init:
        config:
          files:
            '/etc/systemd/system/node-drain.service':
              content: !Sub |
                [Unit]
                Description="manage k8s node draining on shutdown"
                Requires=network.target
                After=network.target
                ConditionPathExists=/var/lib/kubelet/kubeconfig

                [Service]
                Type=simple
                Environment="KUBECONFIG=/var/lib/kubelet/kubeconfig"
                ExecStart=/bin/bash -c 'kubectl uncordon $(hostname)'
                ExecStop=/bin/bash -c 'kubectl drain --ignore-daemonsets --delete-local-data --timeout=29s $(hostname)'
                RemainAfterExit=true
                TimeoutStopSec=30s

                [Install]
                WantedBy=multi-user.target
          mode: '000400'
          owner: root
          group: root
    Properties:
      AssociatePublicIpAddress: false
      IamInstanceProfile: !Ref 'NodeInstanceProfile'
      ImageId: !Ref NodeImageId
      InstanceType: !Ref NodeInstanceType
      KeyName: !Ref NodeSshKeyName
      SecurityGroups:
        - Fn::ImportValue:
            !Sub KubeCluster-NodeSecurityGroup-${ClusterName}
        - Fn::ImportValue:
            !Sub KubeCluster-BastionAccessSecurityGroup-${VpcName}
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: !Ref NodeVolumeSize
            VolumeType: gp2
            DeleteOnTermination: true
      UserData:
        Fn::Base64:
          !Sub |
            #!/bin/bash
            set -o xtrace
            /etc/eks/bootstrap.sh ${ClusterName} ${BootstrapArguments}
            /opt/aws/bin/cfn-signal --exit-code $? \
                     --stack  ${AWS::StackName} \
                     --resource NodeGroup  \
                     --region ${AWS::Region}
            # real programmers sleep :)
            sleep 60
            KUBECONFIG=/var/lib/kubelet/kubeconfig kubectl label node ${!HOSTNAME} node-role.kubernetes.io/node="" --overwrite=true
            systemctl enable node-drain
            systemctl start node-drain

  PolicyStackSignal:
    Type: AWS::IAM::Policy
    Properties:
      PolicyDocument:
        Statement:
          - Action:
              - cloudformation:SignalResource
            Effect: Allow
            Resource: !Join
              - ':'
              - - arn:aws:cloudformation
                - !Ref 'AWS::Region'
                - !Ref 'AWS::AccountId'
                - !Join
                  - /
                  - - stack
                    - !Ref 'AWS::StackName'
                    - '*'
        Version: '2012-10-17'
      PolicyName: !Sub '${AWS::StackName}-PolicyStackSignal'
      Roles:
        - Fn::ImportValue:
            !Sub KubeCluster-NodeInstanceRole-${ClusterName}
